{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9525429,"sourceType":"datasetVersion","datasetId":5574993}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import KFold\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, jaccard_score, matthews_corrcoef, roc_curve, auc","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-08T17:23:00.541248Z","iopub.execute_input":"2024-11-08T17:23:00.541668Z","iopub.status.idle":"2024-11-08T17:23:14.976246Z","shell.execute_reply.started":"2024-11-08T17:23:00.541625Z","shell.execute_reply":"2024-11-08T17:23:14.975271Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"def load_images_from_dir(dir_path):\n    images = []\n    labels = []\n    for class_dir in os.listdir(dir_path):\n        class_path = os.path.join(dir_path, class_dir)\n        label = 1 if class_dir.lower() == 'fire' else 0\n        for filename in os.listdir(class_path):\n            img_path = os.path.join(class_path, filename)\n            img = load_img(img_path, target_size=(150, 150))\n            img_array = img_to_array(img)\n            images.append(img_array)\n            labels.append(label)\n    return np.array(images), np.array(labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T17:23:14.978154Z","iopub.execute_input":"2024-11-08T17:23:14.979362Z","iopub.status.idle":"2024-11-08T17:23:14.987206Z","shell.execute_reply.started":"2024-11-08T17:23:14.979313Z","shell.execute_reply":"2024-11-08T17:23:14.986176Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"original_dir = '/kaggle/input/forest-fire-classification-dataset/ForestFireDataset(Classifications)/ForestFireDataset/train'\ngenerated_dir = '/kaggle/input/forest-fire-classification-dataset/forest_fire_diffusion_generated/forest_fire_diffusion_generated'\n\noriginal_images, original_labels = load_images_from_dir(original_dir)\ngenerated_images, generated_labels = load_images_from_dir(generated_dir)\n\nall_images = np.concatenate([original_images, generated_images], axis=0)\nall_labels = np.concatenate([original_labels, generated_labels], axis=0)\n\nall_images = all_images.astype('float32') / 255.0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T17:23:16.063012Z","iopub.execute_input":"2024-11-08T17:23:16.063893Z","iopub.status.idle":"2024-11-08T17:25:29.839803Z","shell.execute_reply.started":"2024-11-08T17:23:16.063840Z","shell.execute_reply":"2024-11-08T17:25:29.838945Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"print(f\"Total images: {len(all_images)}, Total labels: {len(all_labels)}\")\n\nunique, counts = np.unique(all_labels, return_counts=True)\nprint(f\"All labels distribution: {dict(zip(unique, counts))}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T17:25:29.841355Z","iopub.execute_input":"2024-11-08T17:25:29.841690Z","iopub.status.idle":"2024-11-08T17:25:29.849428Z","shell.execute_reply.started":"2024-11-08T17:25:29.841659Z","shell.execute_reply":"2024-11-08T17:25:29.848411Z"}},"outputs":[{"name":"stdout","text":"Total images: 5148, Total labels: 5148\nAll labels distribution: {0: 2456, 1: 2692}\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import numpy as np\nimport os\nimport time\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout, Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.metrics import (confusion_matrix, precision_score, recall_score, \n                             f1_score, jaccard_score, matthews_corrcoef)\nfrom sklearn.model_selection import KFold\n\ndef create_model_cnn(learning_rate=0.0001):\n    input_layer = Input(shape=(150, 150, 3))\n    x = Conv2D(32, (3, 3), activation='relu')(input_layer)\n    x = MaxPooling2D(pool_size=(2, 2))(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(64, (3, 3), activation='relu')(x)\n    x = MaxPooling2D(pool_size=(2, 2))(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(128, (3, 3), activation='relu')(x)\n    x = MaxPooling2D(pool_size=(2, 2))(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(256, (3, 3), activation='relu')(x)\n    x = MaxPooling2D(pool_size=(2, 2))(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(512, (3, 3), activation='relu')(x)\n    x = MaxPooling2D(pool_size=(2, 2))(x)\n    x = BatchNormalization()(x)\n    x = Flatten()(x)\n    x = Dense(512, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    x = Dense(256, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    output_layer = Dense(1, activation='sigmoid')(x)\n    model = Model(inputs=input_layer, outputs=output_layer)\n    model.compile(optimizer=Adam(learning_rate=learning_rate), \n                  loss='binary_crossentropy', \n                  metrics=['accuracy'])\n    return model\n\nk = 5\nkf = KFold(n_splits=k, shuffle=True, random_state=42)\n\nfold_train_loss = []\nfold_val_loss = []\nfold_train_acc = []\nfold_val_acc = []\nconfusion_matrices = []\nprecision_list = []\nrecall_list = []\nf1_list = []\njaccard_list = []\nmcc_list = []\nmodel_sizes = []\ntrain_times = []\ninference_times = []\n\nall_labels = np.array(all_labels)\nall_images = np.array(all_images)\n\nfold_num = 1\nfor train_index, val_index in kf.split(all_images):\n    print(f\"Fold {fold_num}\")\n    X_train, X_val = all_images[train_index], all_images[val_index]\n    y_train, y_val = all_labels[train_index], all_labels[val_index]\n    start_time = time.time()\n    model = create_model_cnn(learning_rate=0.0001)\n    model_creation_time = time.time() - start_time\n    print(f\"Model creation time: {model_creation_time:.2f} seconds\")\n    total_params = model.count_params()\n    print(f\"Number of Parameters in fold {fold_num}: {total_params}\")\n    model_file_path = f\"model_fold_{fold_num}.h5\"\n    model.save(model_file_path)\n    model_size = os.path.getsize(model_file_path) / (1024 * 1024)\n    print(f\"Model size for fold {fold_num}: {model_size:.2f} MB\")\n    model_sizes.append(model_size)\n    os.remove(model_file_path)\n    datagen = ImageDataGenerator(rotation_range=5, width_shift_range=0.1,\n                                 height_shift_range=0.1, shear_range=0.1,\n                                 zoom_range=0.1, horizontal_flip=True)\n    datagen.fit(X_train)\n    early_stopping = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n    start_time = time.time()\n    history = model.fit(datagen.flow(X_train, y_train, batch_size=32), \n                        validation_data=(X_val, y_val), \n                        epochs=50, \n                        callbacks=[early_stopping],\n                        verbose=1)\n    train_time = time.time() - start_time\n    train_times.append(train_time)\n    start_time = time.time()\n    val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n    inference_time = time.time() - start_time\n    inference_times.append(inference_time)\n    fold_train_loss.append(history.history['loss'])\n    fold_val_loss.append(history.history['val_loss'])\n    fold_train_acc.append(history.history['accuracy'])\n    fold_val_acc.append(history.history['val_accuracy'])\n    y_val_pred = model.predict(X_val, verbose=0)\n    y_val_pred_class = np.where(y_val_pred > 0.5, 1, 0).flatten()\n    confusion_matrices.append(confusion_matrix(y_val, y_val_pred_class))\n    precision = precision_score(y_val, y_val_pred_class)\n    recall = recall_score(y_val, y_val_pred_class)\n    f1 = f1_score(y_val, y_val_pred_class)\n    jaccard = jaccard_score(y_val, y_val_pred_class)\n    mcc = matthews_corrcoef(y_val, y_val_pred_class)\n    precision_list.append(precision)\n    recall_list.append(recall)\n    f1_list.append(f1)\n    jaccard_list.append(jaccard)\n    mcc_list.append(mcc)\n    fold_num += 1\n\naverage_precision = np.mean(precision_list)\naverage_recall = np.mean(recall_list)\naverage_f1 = np.mean(f1_list)\naverage_jaccard = np.mean(jaccard_list)\naverage_mcc = np.mean(mcc_list)\naverage_model_size = np.mean(model_sizes)\naverage_train_time = np.mean(train_times)\naverage_inference_time = np.mean(inference_times)\n\naverage_train_loss = np.mean([loss[-1] for loss in fold_train_loss])\naverage_val_loss = np.mean([loss[-1] for loss in fold_val_loss])\naverage_train_acc = np.mean([acc[-1] for acc in fold_train_acc])\naverage_val_acc = np.mean([acc[-1] for acc in fold_val_acc])\n\nprint(f\"\\nAverage Training Loss: {average_train_loss:.4f}\")\nprint(f\"Average Validation Loss: {average_val_loss:.4f}\")\nprint(f\"Average Training Accuracy: {average_train_acc:.4f}\")\nprint(f\"Average Validation Accuracy: {average_val_acc:.4f}\")\nprint(f\"Average Precision: {average_precision:.4f}\")\nprint(f\"Average Recall: {average_recall:.4f}\")\nprint(f\"Average F1 Score: {average_f1:.4f}\")\nprint(f\"Average Jaccard Index: {average_jaccard:.4f}\")\nprint(f\"Average MCC: {average_mcc:.4f}\")\nprint(f\"Average Model Size: {average_model_size:.2f} MB\")\nprint(f\"Average Training Time: {average_train_time:.2f} seconds\")\nprint(f\"Average Inference Time: {average_inference_time:.2f} seconds\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T17:29:16.464596Z","iopub.execute_input":"2024-11-08T17:29:16.465416Z","iopub.status.idle":"2024-11-08T18:54:04.880004Z","shell.execute_reply.started":"2024-11-08T17:29:16.465373Z","shell.execute_reply":"2024-11-08T18:54:04.878872Z"}},"outputs":[{"name":"stdout","text":"Fold 1\nModel creation time: 0.80 seconds\nNumber of Parameters in fold 1: 2753217\nModel size for fold 1: 10.58 MB\nEpoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1731086963.812180     112 service.cc:145] XLA service 0x7b3424004410 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1731086963.812251     112 service.cc:153]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  3/129\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 82ms/step - accuracy: 0.5920 - loss: 0.9784 ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1731086971.639125     112 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 206ms/step - accuracy: 0.7695 - loss: 0.5702 - val_accuracy: 0.4951 - val_loss: 0.6682\nEpoch 2/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 141ms/step - accuracy: 0.8692 - loss: 0.3420 - val_accuracy: 0.7932 - val_loss: 0.4930\nEpoch 3/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 142ms/step - accuracy: 0.8854 - loss: 0.3042 - val_accuracy: 0.8592 - val_loss: 0.3436\nEpoch 4/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9001 - loss: 0.2675 - val_accuracy: 0.9136 - val_loss: 0.2149\nEpoch 5/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 142ms/step - accuracy: 0.9342 - loss: 0.2031 - val_accuracy: 0.9029 - val_loss: 0.2528\nEpoch 6/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9324 - loss: 0.1819 - val_accuracy: 0.9466 - val_loss: 0.1481\nEpoch 7/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9313 - loss: 0.1930 - val_accuracy: 0.9515 - val_loss: 0.1421\nEpoch 8/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 141ms/step - accuracy: 0.9361 - loss: 0.1876 - val_accuracy: 0.9485 - val_loss: 0.1420\nEpoch 9/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 141ms/step - accuracy: 0.9391 - loss: 0.1769 - val_accuracy: 0.9583 - val_loss: 0.1236\nEpoch 10/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 142ms/step - accuracy: 0.9533 - loss: 0.1244 - val_accuracy: 0.9388 - val_loss: 0.1779\nEpoch 11/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 141ms/step - accuracy: 0.9489 - loss: 0.1583 - val_accuracy: 0.9544 - val_loss: 0.1459\nEpoch 12/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9627 - loss: 0.1125 - val_accuracy: 0.9515 - val_loss: 0.1439\nEpoch 13/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 141ms/step - accuracy: 0.9564 - loss: 0.1189 - val_accuracy: 0.9583 - val_loss: 0.1252\nEpoch 14/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 141ms/step - accuracy: 0.9597 - loss: 0.1244 - val_accuracy: 0.9660 - val_loss: 0.1008\nEpoch 15/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 141ms/step - accuracy: 0.9575 - loss: 0.1192 - val_accuracy: 0.9379 - val_loss: 0.1790\nEpoch 16/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9609 - loss: 0.1159 - val_accuracy: 0.9612 - val_loss: 0.1060\nEpoch 17/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9633 - loss: 0.0973 - val_accuracy: 0.9583 - val_loss: 0.1260\nEpoch 18/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 144ms/step - accuracy: 0.9585 - loss: 0.1124 - val_accuracy: 0.9641 - val_loss: 0.1202\nEpoch 19/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9586 - loss: 0.1098 - val_accuracy: 0.9680 - val_loss: 0.0998\nEpoch 20/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 141ms/step - accuracy: 0.9726 - loss: 0.0833 - val_accuracy: 0.9621 - val_loss: 0.1201\nEpoch 21/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 141ms/step - accuracy: 0.9698 - loss: 0.0772 - val_accuracy: 0.9660 - val_loss: 0.1111\nEpoch 22/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 141ms/step - accuracy: 0.9729 - loss: 0.0776 - val_accuracy: 0.9689 - val_loss: 0.1067\nEpoch 23/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 141ms/step - accuracy: 0.9652 - loss: 0.0977 - val_accuracy: 0.9592 - val_loss: 0.1323\nEpoch 24/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9701 - loss: 0.0940 - val_accuracy: 0.9709 - val_loss: 0.1021\nEpoch 25/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9684 - loss: 0.0950 - val_accuracy: 0.9670 - val_loss: 0.1042\nEpoch 26/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9747 - loss: 0.0752 - val_accuracy: 0.9689 - val_loss: 0.0978\nEpoch 27/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9720 - loss: 0.0725 - val_accuracy: 0.9699 - val_loss: 0.1128\nEpoch 28/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9761 - loss: 0.0708 - val_accuracy: 0.9728 - val_loss: 0.1051\nEpoch 29/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9810 - loss: 0.0633 - val_accuracy: 0.9680 - val_loss: 0.1354\nEpoch 30/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 139ms/step - accuracy: 0.9692 - loss: 0.0836 - val_accuracy: 0.9699 - val_loss: 0.1024\nEpoch 31/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 141ms/step - accuracy: 0.9694 - loss: 0.0970 - val_accuracy: 0.9689 - val_loss: 0.1056\nEpoch 32/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9785 - loss: 0.0599 - val_accuracy: 0.9748 - val_loss: 0.1114\nEpoch 33/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9769 - loss: 0.0677 - val_accuracy: 0.9641 - val_loss: 0.1213\nEpoch 34/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 141ms/step - accuracy: 0.9724 - loss: 0.0764 - val_accuracy: 0.9689 - val_loss: 0.1127\nEpoch 35/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 141ms/step - accuracy: 0.9728 - loss: 0.0848 - val_accuracy: 0.9680 - val_loss: 0.1035\nEpoch 36/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 141ms/step - accuracy: 0.9760 - loss: 0.0674 - val_accuracy: 0.9689 - val_loss: 0.1161\nEpoch 37/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9796 - loss: 0.0651 - val_accuracy: 0.9718 - val_loss: 0.1264\nEpoch 38/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 139ms/step - accuracy: 0.9837 - loss: 0.0526 - val_accuracy: 0.9728 - val_loss: 0.0876\nEpoch 39/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 141ms/step - accuracy: 0.9860 - loss: 0.0443 - val_accuracy: 0.9689 - val_loss: 0.1048\nEpoch 40/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 141ms/step - accuracy: 0.9756 - loss: 0.0754 - val_accuracy: 0.9709 - val_loss: 0.1180\nEpoch 41/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 142ms/step - accuracy: 0.9815 - loss: 0.0575 - val_accuracy: 0.9748 - val_loss: 0.0845\nEpoch 42/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9858 - loss: 0.0462 - val_accuracy: 0.9718 - val_loss: 0.1058\nEpoch 43/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9808 - loss: 0.0538 - val_accuracy: 0.9767 - val_loss: 0.0989\nEpoch 44/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 141ms/step - accuracy: 0.9853 - loss: 0.0462 - val_accuracy: 0.9767 - val_loss: 0.0930\nEpoch 45/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 139ms/step - accuracy: 0.9835 - loss: 0.0540 - val_accuracy: 0.9718 - val_loss: 0.0934\nEpoch 46/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 142ms/step - accuracy: 0.9785 - loss: 0.0641 - val_accuracy: 0.9602 - val_loss: 0.1159\nEpoch 47/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9836 - loss: 0.0604 - val_accuracy: 0.9777 - val_loss: 0.1051\nEpoch 48/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 142ms/step - accuracy: 0.9787 - loss: 0.0548 - val_accuracy: 0.9748 - val_loss: 0.0902\nEpoch 49/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9803 - loss: 0.0556 - val_accuracy: 0.9738 - val_loss: 0.0898\nEpoch 50/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 139ms/step - accuracy: 0.9886 - loss: 0.0335 - val_accuracy: 0.9699 - val_loss: 0.0953\nFold 2\nModel creation time: 0.11 seconds\nNumber of Parameters in fold 2: 2753217\nModel size for fold 2: 10.58 MB\nEpoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 191ms/step - accuracy: 0.7517 - loss: 0.6179 - val_accuracy: 0.5417 - val_loss: 0.6531\nEpoch 2/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.8581 - loss: 0.3764 - val_accuracy: 0.7748 - val_loss: 0.4675\nEpoch 3/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.8902 - loss: 0.2993 - val_accuracy: 0.8816 - val_loss: 0.3003\nEpoch 4/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 139ms/step - accuracy: 0.9046 - loss: 0.2439 - val_accuracy: 0.9388 - val_loss: 0.1733\nEpoch 5/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 141ms/step - accuracy: 0.9145 - loss: 0.2263 - val_accuracy: 0.9573 - val_loss: 0.1161\nEpoch 6/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9309 - loss: 0.2189 - val_accuracy: 0.9612 - val_loss: 0.1195\nEpoch 7/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 144ms/step - accuracy: 0.9300 - loss: 0.1793 - val_accuracy: 0.9252 - val_loss: 0.1870\nEpoch 8/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 142ms/step - accuracy: 0.9269 - loss: 0.2020 - val_accuracy: 0.9612 - val_loss: 0.0978\nEpoch 9/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 142ms/step - accuracy: 0.9473 - loss: 0.1518 - val_accuracy: 0.9728 - val_loss: 0.0827\nEpoch 10/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 142ms/step - accuracy: 0.9418 - loss: 0.1591 - val_accuracy: 0.9379 - val_loss: 0.1623\nEpoch 11/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 141ms/step - accuracy: 0.9444 - loss: 0.1534 - val_accuracy: 0.9748 - val_loss: 0.0847\nEpoch 12/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 142ms/step - accuracy: 0.9502 - loss: 0.1366 - val_accuracy: 0.9718 - val_loss: 0.0818\nEpoch 13/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 141ms/step - accuracy: 0.9576 - loss: 0.1285 - val_accuracy: 0.9602 - val_loss: 0.1035\nEpoch 14/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9547 - loss: 0.1265 - val_accuracy: 0.9796 - val_loss: 0.0707\nEpoch 15/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9511 - loss: 0.1269 - val_accuracy: 0.9689 - val_loss: 0.0752\nEpoch 16/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 141ms/step - accuracy: 0.9622 - loss: 0.1086 - val_accuracy: 0.9777 - val_loss: 0.0662\nEpoch 17/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9596 - loss: 0.1162 - val_accuracy: 0.9738 - val_loss: 0.0696\nEpoch 18/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 141ms/step - accuracy: 0.9568 - loss: 0.1101 - val_accuracy: 0.9680 - val_loss: 0.0913\nEpoch 19/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 139ms/step - accuracy: 0.9662 - loss: 0.1013 - val_accuracy: 0.9796 - val_loss: 0.0600\nEpoch 20/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 139ms/step - accuracy: 0.9669 - loss: 0.0978 - val_accuracy: 0.9767 - val_loss: 0.0693\nEpoch 21/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9714 - loss: 0.0869 - val_accuracy: 0.9786 - val_loss: 0.0714\nEpoch 22/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9697 - loss: 0.0884 - val_accuracy: 0.9728 - val_loss: 0.0765\nEpoch 23/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9616 - loss: 0.1079 - val_accuracy: 0.9767 - val_loss: 0.0629\nEpoch 24/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9730 - loss: 0.0827 - val_accuracy: 0.9767 - val_loss: 0.0661\nEpoch 25/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 139ms/step - accuracy: 0.9754 - loss: 0.0855 - val_accuracy: 0.9728 - val_loss: 0.0796\nEpoch 26/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 141ms/step - accuracy: 0.9716 - loss: 0.0858 - val_accuracy: 0.9748 - val_loss: 0.0643\nEpoch 27/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9749 - loss: 0.0819 - val_accuracy: 0.9631 - val_loss: 0.1000\nEpoch 28/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9722 - loss: 0.0825 - val_accuracy: 0.9660 - val_loss: 0.0830\nEpoch 29/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 139ms/step - accuracy: 0.9649 - loss: 0.0919 - val_accuracy: 0.9806 - val_loss: 0.0594\nEpoch 30/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 139ms/step - accuracy: 0.9727 - loss: 0.0753 - val_accuracy: 0.9757 - val_loss: 0.0628\nEpoch 31/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9762 - loss: 0.0758 - val_accuracy: 0.9777 - val_loss: 0.0570\nEpoch 32/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 139ms/step - accuracy: 0.9792 - loss: 0.0664 - val_accuracy: 0.9748 - val_loss: 0.0688\nEpoch 33/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9749 - loss: 0.0735 - val_accuracy: 0.9796 - val_loss: 0.0682\nEpoch 34/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 139ms/step - accuracy: 0.9768 - loss: 0.0611 - val_accuracy: 0.9835 - val_loss: 0.0492\nEpoch 35/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 139ms/step - accuracy: 0.9778 - loss: 0.0658 - val_accuracy: 0.9806 - val_loss: 0.0602\nEpoch 36/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9755 - loss: 0.0639 - val_accuracy: 0.9748 - val_loss: 0.0689\nEpoch 37/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 138ms/step - accuracy: 0.9774 - loss: 0.0631 - val_accuracy: 0.9748 - val_loss: 0.0680\nEpoch 38/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9752 - loss: 0.0777 - val_accuracy: 0.9854 - val_loss: 0.0423\nEpoch 39/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 139ms/step - accuracy: 0.9814 - loss: 0.0640 - val_accuracy: 0.9816 - val_loss: 0.0481\nEpoch 40/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 139ms/step - accuracy: 0.9766 - loss: 0.0647 - val_accuracy: 0.9777 - val_loss: 0.0560\nEpoch 41/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9816 - loss: 0.0528 - val_accuracy: 0.9757 - val_loss: 0.0697\nEpoch 42/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 139ms/step - accuracy: 0.9762 - loss: 0.0580 - val_accuracy: 0.9806 - val_loss: 0.0540\nEpoch 43/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9786 - loss: 0.0558 - val_accuracy: 0.9796 - val_loss: 0.0551\nEpoch 44/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9832 - loss: 0.0544 - val_accuracy: 0.9835 - val_loss: 0.0509\nEpoch 45/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 139ms/step - accuracy: 0.9813 - loss: 0.0517 - val_accuracy: 0.9786 - val_loss: 0.0493\nEpoch 46/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9813 - loss: 0.0633 - val_accuracy: 0.9738 - val_loss: 0.0673\nEpoch 47/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 139ms/step - accuracy: 0.9778 - loss: 0.0799 - val_accuracy: 0.9786 - val_loss: 0.0657\nEpoch 48/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9789 - loss: 0.0634 - val_accuracy: 0.9777 - val_loss: 0.0602\nEpoch 49/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 141ms/step - accuracy: 0.9853 - loss: 0.0414 - val_accuracy: 0.9796 - val_loss: 0.0551\nEpoch 50/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 139ms/step - accuracy: 0.9847 - loss: 0.0465 - val_accuracy: 0.9757 - val_loss: 0.0786\nFold 3\nModel creation time: 0.11 seconds\nNumber of Parameters in fold 3: 2753217\nModel size for fold 3: 10.58 MB\nEpoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 185ms/step - accuracy: 0.7667 - loss: 0.5597 - val_accuracy: 0.4534 - val_loss: 0.7615\nEpoch 2/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 142ms/step - accuracy: 0.8781 - loss: 0.3208 - val_accuracy: 0.6563 - val_loss: 0.6089\nEpoch 3/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 139ms/step - accuracy: 0.9118 - loss: 0.2527 - val_accuracy: 0.8126 - val_loss: 0.4423\nEpoch 4/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9131 - loss: 0.2638 - val_accuracy: 0.8660 - val_loss: 0.3435\nEpoch 5/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9204 - loss: 0.2311 - val_accuracy: 0.9282 - val_loss: 0.1994\nEpoch 6/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 138ms/step - accuracy: 0.9326 - loss: 0.1975 - val_accuracy: 0.9534 - val_loss: 0.1426\nEpoch 7/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 141ms/step - accuracy: 0.9394 - loss: 0.1763 - val_accuracy: 0.9388 - val_loss: 0.1707\nEpoch 8/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 140ms/step - accuracy: 0.9346 - loss: 0.1901 - val_accuracy: 0.9379 - val_loss: 0.1841\nEpoch 9/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 141ms/step - accuracy: 0.9481 - loss: 0.1611 - val_accuracy: 0.9573 - val_loss: 0.1194\nEpoch 10/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 141ms/step - accuracy: 0.9408 - loss: 0.1663 - val_accuracy: 0.9524 - val_loss: 0.1362\nEpoch 11/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 142ms/step - accuracy: 0.9551 - loss: 0.1204 - val_accuracy: 0.9515 - val_loss: 0.1412\nEpoch 12/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 142ms/step - accuracy: 0.9532 - loss: 0.1391 - val_accuracy: 0.9592 - val_loss: 0.1172\nEpoch 13/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 144ms/step - accuracy: 0.9498 - loss: 0.1481 - val_accuracy: 0.9612 - val_loss: 0.1031\nEpoch 14/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 142ms/step - accuracy: 0.9576 - loss: 0.1215 - val_accuracy: 0.9592 - val_loss: 0.1124\nEpoch 15/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 153ms/step - accuracy: 0.9540 - loss: 0.1262 - val_accuracy: 0.9485 - val_loss: 0.1532\nEpoch 16/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 151ms/step - accuracy: 0.9636 - loss: 0.1038 - val_accuracy: 0.9650 - val_loss: 0.1040\nEpoch 17/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 148ms/step - accuracy: 0.9630 - loss: 0.1039 - val_accuracy: 0.9631 - val_loss: 0.1019\nEpoch 18/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 150ms/step - accuracy: 0.9647 - loss: 0.1070 - val_accuracy: 0.9641 - val_loss: 0.1088\nEpoch 19/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 147ms/step - accuracy: 0.9605 - loss: 0.1050 - val_accuracy: 0.9689 - val_loss: 0.0959\nEpoch 20/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 150ms/step - accuracy: 0.9655 - loss: 0.1127 - val_accuracy: 0.9602 - val_loss: 0.1150\nEpoch 21/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 150ms/step - accuracy: 0.9561 - loss: 0.1161 - val_accuracy: 0.9699 - val_loss: 0.0945\nEpoch 22/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.9642 - loss: 0.1023 - val_accuracy: 0.9709 - val_loss: 0.0980\nEpoch 23/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.9658 - loss: 0.0933 - val_accuracy: 0.9583 - val_loss: 0.1293\nEpoch 24/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.9710 - loss: 0.0841 - val_accuracy: 0.9650 - val_loss: 0.1146\nEpoch 25/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.9668 - loss: 0.0980 - val_accuracy: 0.9718 - val_loss: 0.0865\nEpoch 26/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 147ms/step - accuracy: 0.9764 - loss: 0.0738 - val_accuracy: 0.9689 - val_loss: 0.0988\nEpoch 27/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 150ms/step - accuracy: 0.9692 - loss: 0.0877 - val_accuracy: 0.9660 - val_loss: 0.0925\nEpoch 28/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 147ms/step - accuracy: 0.9769 - loss: 0.0727 - val_accuracy: 0.9660 - val_loss: 0.0963\nEpoch 29/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.9724 - loss: 0.0818 - val_accuracy: 0.9456 - val_loss: 0.1457\nEpoch 30/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.9753 - loss: 0.0658 - val_accuracy: 0.9660 - val_loss: 0.0975\nEpoch 31/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 148ms/step - accuracy: 0.9736 - loss: 0.0734 - val_accuracy: 0.9748 - val_loss: 0.0758\nEpoch 32/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 151ms/step - accuracy: 0.9817 - loss: 0.0670 - val_accuracy: 0.9728 - val_loss: 0.0987\nEpoch 33/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.9759 - loss: 0.0610 - val_accuracy: 0.9738 - val_loss: 0.0913\nEpoch 34/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 148ms/step - accuracy: 0.9807 - loss: 0.0642 - val_accuracy: 0.9748 - val_loss: 0.0906\nEpoch 35/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 148ms/step - accuracy: 0.9755 - loss: 0.0831 - val_accuracy: 0.9631 - val_loss: 0.1128\nEpoch 36/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 148ms/step - accuracy: 0.9780 - loss: 0.0706 - val_accuracy: 0.9748 - val_loss: 0.0879\nEpoch 37/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.9761 - loss: 0.0629 - val_accuracy: 0.9738 - val_loss: 0.0815\nEpoch 38/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.9787 - loss: 0.0618 - val_accuracy: 0.9757 - val_loss: 0.0777\nEpoch 39/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 150ms/step - accuracy: 0.9836 - loss: 0.0464 - val_accuracy: 0.9738 - val_loss: 0.0801\nEpoch 40/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 150ms/step - accuracy: 0.9822 - loss: 0.0492 - val_accuracy: 0.9796 - val_loss: 0.0866\nEpoch 41/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 152ms/step - accuracy: 0.9783 - loss: 0.0561 - val_accuracy: 0.9612 - val_loss: 0.1291\nEpoch 42/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 151ms/step - accuracy: 0.9829 - loss: 0.0497 - val_accuracy: 0.9728 - val_loss: 0.1085\nEpoch 43/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 152ms/step - accuracy: 0.9784 - loss: 0.0624 - val_accuracy: 0.9806 - val_loss: 0.0697\nEpoch 44/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 153ms/step - accuracy: 0.9820 - loss: 0.0636 - val_accuracy: 0.9757 - val_loss: 0.0721\nEpoch 45/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 150ms/step - accuracy: 0.9852 - loss: 0.0476 - val_accuracy: 0.9689 - val_loss: 0.1139\nEpoch 46/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.9821 - loss: 0.0461 - val_accuracy: 0.9796 - val_loss: 0.0754\nEpoch 47/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 148ms/step - accuracy: 0.9819 - loss: 0.0510 - val_accuracy: 0.9748 - val_loss: 0.0732\nEpoch 48/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.9792 - loss: 0.0554 - val_accuracy: 0.9631 - val_loss: 0.1331\nEpoch 49/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 150ms/step - accuracy: 0.9815 - loss: 0.0621 - val_accuracy: 0.9660 - val_loss: 0.0998\nEpoch 50/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 148ms/step - accuracy: 0.9775 - loss: 0.0613 - val_accuracy: 0.9777 - val_loss: 0.0797\nFold 4\nModel creation time: 0.12 seconds\nNumber of Parameters in fold 4: 2753217\nModel size for fold 4: 10.58 MB\nEpoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 214ms/step - accuracy: 0.7621 - loss: 0.6026 - val_accuracy: 0.5044 - val_loss: 0.6740\nEpoch 2/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 148ms/step - accuracy: 0.8761 - loss: 0.3449 - val_accuracy: 0.8533 - val_loss: 0.4932\nEpoch 3/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 150ms/step - accuracy: 0.9025 - loss: 0.2835 - val_accuracy: 0.7891 - val_loss: 0.4110\nEpoch 4/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 151ms/step - accuracy: 0.9099 - loss: 0.2627 - val_accuracy: 0.9242 - val_loss: 0.2106\nEpoch 5/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.9175 - loss: 0.2278 - val_accuracy: 0.9427 - val_loss: 0.1884\nEpoch 6/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 152ms/step - accuracy: 0.9197 - loss: 0.2205 - val_accuracy: 0.9524 - val_loss: 0.1811\nEpoch 7/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 152ms/step - accuracy: 0.9256 - loss: 0.1920 - val_accuracy: 0.9466 - val_loss: 0.1762\nEpoch 8/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 150ms/step - accuracy: 0.9459 - loss: 0.1553 - val_accuracy: 0.9475 - val_loss: 0.1531\nEpoch 9/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 151ms/step - accuracy: 0.9345 - loss: 0.1774 - val_accuracy: 0.9495 - val_loss: 0.1765\nEpoch 10/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.9494 - loss: 0.1373 - val_accuracy: 0.9475 - val_loss: 0.1560\nEpoch 11/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 148ms/step - accuracy: 0.9493 - loss: 0.1402 - val_accuracy: 0.9572 - val_loss: 0.1327\nEpoch 12/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.9489 - loss: 0.1506 - val_accuracy: 0.9592 - val_loss: 0.1443\nEpoch 13/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 148ms/step - accuracy: 0.9510 - loss: 0.1319 - val_accuracy: 0.9495 - val_loss: 0.1322\nEpoch 14/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.9492 - loss: 0.1361 - val_accuracy: 0.9563 - val_loss: 0.1177\nEpoch 15/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.9523 - loss: 0.1350 - val_accuracy: 0.9640 - val_loss: 0.1031\nEpoch 16/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 151ms/step - accuracy: 0.9617 - loss: 0.1136 - val_accuracy: 0.9592 - val_loss: 0.1231\nEpoch 17/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 151ms/step - accuracy: 0.9627 - loss: 0.1058 - val_accuracy: 0.9699 - val_loss: 0.0913\nEpoch 18/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.9581 - loss: 0.1139 - val_accuracy: 0.9631 - val_loss: 0.1116\nEpoch 19/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.9565 - loss: 0.1196 - val_accuracy: 0.9689 - val_loss: 0.0884\nEpoch 20/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 150ms/step - accuracy: 0.9606 - loss: 0.1099 - val_accuracy: 0.9631 - val_loss: 0.1067\nEpoch 21/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 151ms/step - accuracy: 0.9703 - loss: 0.0862 - val_accuracy: 0.9728 - val_loss: 0.0825\nEpoch 22/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 153ms/step - accuracy: 0.9657 - loss: 0.0979 - val_accuracy: 0.9679 - val_loss: 0.0847\nEpoch 23/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 151ms/step - accuracy: 0.9716 - loss: 0.0867 - val_accuracy: 0.9660 - val_loss: 0.1076\nEpoch 24/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 153ms/step - accuracy: 0.9714 - loss: 0.0892 - val_accuracy: 0.9699 - val_loss: 0.0920\nEpoch 25/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 153ms/step - accuracy: 0.9705 - loss: 0.0932 - val_accuracy: 0.9708 - val_loss: 0.0798\nEpoch 26/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 151ms/step - accuracy: 0.9739 - loss: 0.0798 - val_accuracy: 0.9689 - val_loss: 0.0934\nEpoch 27/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 152ms/step - accuracy: 0.9686 - loss: 0.0866 - val_accuracy: 0.9611 - val_loss: 0.1069\nEpoch 28/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 152ms/step - accuracy: 0.9676 - loss: 0.0823 - val_accuracy: 0.9495 - val_loss: 0.1691\nEpoch 29/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 150ms/step - accuracy: 0.9698 - loss: 0.0829 - val_accuracy: 0.9670 - val_loss: 0.1139\nEpoch 30/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 151ms/step - accuracy: 0.9731 - loss: 0.0802 - val_accuracy: 0.9670 - val_loss: 0.0926\nEpoch 31/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.9709 - loss: 0.0834 - val_accuracy: 0.9660 - val_loss: 0.1009\nEpoch 32/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 148ms/step - accuracy: 0.9720 - loss: 0.0788 - val_accuracy: 0.9699 - val_loss: 0.0971\nEpoch 33/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 151ms/step - accuracy: 0.9768 - loss: 0.0686 - val_accuracy: 0.9796 - val_loss: 0.0609\nEpoch 34/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 151ms/step - accuracy: 0.9766 - loss: 0.0652 - val_accuracy: 0.9738 - val_loss: 0.0784\nEpoch 35/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.9755 - loss: 0.0718 - val_accuracy: 0.9767 - val_loss: 0.0736\nEpoch 36/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 151ms/step - accuracy: 0.9811 - loss: 0.0525 - val_accuracy: 0.9708 - val_loss: 0.0912\nEpoch 37/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.9823 - loss: 0.0603 - val_accuracy: 0.9708 - val_loss: 0.0810\nEpoch 38/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 151ms/step - accuracy: 0.9775 - loss: 0.0715 - val_accuracy: 0.9854 - val_loss: 0.0608\nEpoch 39/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 153ms/step - accuracy: 0.9732 - loss: 0.0701 - val_accuracy: 0.9757 - val_loss: 0.0784\nEpoch 40/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.9801 - loss: 0.0514 - val_accuracy: 0.9825 - val_loss: 0.0636\nEpoch 41/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 151ms/step - accuracy: 0.9786 - loss: 0.0605 - val_accuracy: 0.9796 - val_loss: 0.0615\nEpoch 42/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 150ms/step - accuracy: 0.9785 - loss: 0.0570 - val_accuracy: 0.9767 - val_loss: 0.0758\nEpoch 43/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 150ms/step - accuracy: 0.9805 - loss: 0.0535 - val_accuracy: 0.9679 - val_loss: 0.0805\nEpoch 44/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 151ms/step - accuracy: 0.9789 - loss: 0.0600 - val_accuracy: 0.9738 - val_loss: 0.0734\nEpoch 45/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 148ms/step - accuracy: 0.9783 - loss: 0.0580 - val_accuracy: 0.9738 - val_loss: 0.0841\nEpoch 46/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.9793 - loss: 0.0613 - val_accuracy: 0.9786 - val_loss: 0.0689\nEpoch 47/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 151ms/step - accuracy: 0.9799 - loss: 0.0479 - val_accuracy: 0.9738 - val_loss: 0.0887\nEpoch 48/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 150ms/step - accuracy: 0.9752 - loss: 0.0645 - val_accuracy: 0.9738 - val_loss: 0.0788\nEpoch 49/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 150ms/step - accuracy: 0.9867 - loss: 0.0422 - val_accuracy: 0.9650 - val_loss: 0.1061\nEpoch 50/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.9807 - loss: 0.0570 - val_accuracy: 0.9767 - val_loss: 0.0847\nFold 5\nModel creation time: 0.12 seconds\nNumber of Parameters in fold 5: 2753217\nModel size for fold 5: 10.58 MB\nEpoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 198ms/step - accuracy: 0.7591 - loss: 0.5782 - val_accuracy: 0.4655 - val_loss: 0.8402\nEpoch 2/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.8544 - loss: 0.3800 - val_accuracy: 0.6239 - val_loss: 0.5884\nEpoch 3/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.8841 - loss: 0.3083 - val_accuracy: 0.5607 - val_loss: 0.9409\nEpoch 4/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 152ms/step - accuracy: 0.9138 - loss: 0.2373 - val_accuracy: 0.8814 - val_loss: 0.3242\nEpoch 5/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 155ms/step - accuracy: 0.9110 - loss: 0.2401 - val_accuracy: 0.8824 - val_loss: 0.3053\nEpoch 6/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 153ms/step - accuracy: 0.9269 - loss: 0.1907 - val_accuracy: 0.9339 - val_loss: 0.2169\nEpoch 7/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 152ms/step - accuracy: 0.9325 - loss: 0.1768 - val_accuracy: 0.9475 - val_loss: 0.1785\nEpoch 8/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 152ms/step - accuracy: 0.9395 - loss: 0.1739 - val_accuracy: 0.9504 - val_loss: 0.1614\nEpoch 9/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 154ms/step - accuracy: 0.9465 - loss: 0.1536 - val_accuracy: 0.9524 - val_loss: 0.1499\nEpoch 10/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 152ms/step - accuracy: 0.9495 - loss: 0.1347 - val_accuracy: 0.9572 - val_loss: 0.1417\nEpoch 11/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 151ms/step - accuracy: 0.9603 - loss: 0.1216 - val_accuracy: 0.9553 - val_loss: 0.1564\nEpoch 12/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 150ms/step - accuracy: 0.9505 - loss: 0.1374 - val_accuracy: 0.9534 - val_loss: 0.1381\nEpoch 13/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 150ms/step - accuracy: 0.9518 - loss: 0.1349 - val_accuracy: 0.9436 - val_loss: 0.1855\nEpoch 14/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 148ms/step - accuracy: 0.9480 - loss: 0.1443 - val_accuracy: 0.9543 - val_loss: 0.1594\nEpoch 15/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 151ms/step - accuracy: 0.9547 - loss: 0.1194 - val_accuracy: 0.9611 - val_loss: 0.1310\nEpoch 16/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.9557 - loss: 0.1250 - val_accuracy: 0.9572 - val_loss: 0.1371\nEpoch 17/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.9624 - loss: 0.1213 - val_accuracy: 0.9563 - val_loss: 0.1355\nEpoch 18/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 151ms/step - accuracy: 0.9646 - loss: 0.1031 - val_accuracy: 0.9708 - val_loss: 0.1182\nEpoch 19/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.9643 - loss: 0.1050 - val_accuracy: 0.9621 - val_loss: 0.1179\nEpoch 20/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 151ms/step - accuracy: 0.9672 - loss: 0.0929 - val_accuracy: 0.9553 - val_loss: 0.1369\nEpoch 21/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 151ms/step - accuracy: 0.9630 - loss: 0.0943 - val_accuracy: 0.9553 - val_loss: 0.1526\nEpoch 22/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 148ms/step - accuracy: 0.9683 - loss: 0.0924 - val_accuracy: 0.9621 - val_loss: 0.1255\nEpoch 23/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 151ms/step - accuracy: 0.9708 - loss: 0.0846 - val_accuracy: 0.9310 - val_loss: 0.1606\nEpoch 24/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 152ms/step - accuracy: 0.9692 - loss: 0.0958 - val_accuracy: 0.9339 - val_loss: 0.1941\nEpoch 25/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 151ms/step - accuracy: 0.9722 - loss: 0.0845 - val_accuracy: 0.9708 - val_loss: 0.1190\nEpoch 26/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 148ms/step - accuracy: 0.9710 - loss: 0.0832 - val_accuracy: 0.9563 - val_loss: 0.1354\nEpoch 27/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.9763 - loss: 0.0695 - val_accuracy: 0.9456 - val_loss: 0.1564\nEpoch 28/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 148ms/step - accuracy: 0.9697 - loss: 0.0881 - val_accuracy: 0.9670 - val_loss: 0.1339\nEpoch 29/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 150ms/step - accuracy: 0.9731 - loss: 0.0774 - val_accuracy: 0.9621 - val_loss: 0.1352\nEpoch 30/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.9751 - loss: 0.0727 - val_accuracy: 0.9660 - val_loss: 0.1239\nEpoch 31/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 148ms/step - accuracy: 0.9806 - loss: 0.0642 - val_accuracy: 0.9475 - val_loss: 0.1537\nEpoch 32/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.9818 - loss: 0.0555 - val_accuracy: 0.9718 - val_loss: 0.1129\nEpoch 33/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 151ms/step - accuracy: 0.9727 - loss: 0.0833 - val_accuracy: 0.9640 - val_loss: 0.1211\nEpoch 34/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 150ms/step - accuracy: 0.9778 - loss: 0.0733 - val_accuracy: 0.9708 - val_loss: 0.1019\nEpoch 35/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 152ms/step - accuracy: 0.9782 - loss: 0.0565 - val_accuracy: 0.9738 - val_loss: 0.1037\nEpoch 36/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 153ms/step - accuracy: 0.9735 - loss: 0.0720 - val_accuracy: 0.9592 - val_loss: 0.1286\nEpoch 37/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 151ms/step - accuracy: 0.9848 - loss: 0.0502 - val_accuracy: 0.9689 - val_loss: 0.1189\nEpoch 38/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 148ms/step - accuracy: 0.9747 - loss: 0.0646 - val_accuracy: 0.9495 - val_loss: 0.1671\nEpoch 39/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 154ms/step - accuracy: 0.9771 - loss: 0.0629 - val_accuracy: 0.9670 - val_loss: 0.1421\nEpoch 40/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 153ms/step - accuracy: 0.9769 - loss: 0.0716 - val_accuracy: 0.9621 - val_loss: 0.1389\nEpoch 41/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 151ms/step - accuracy: 0.9790 - loss: 0.0620 - val_accuracy: 0.9602 - val_loss: 0.1347\nEpoch 42/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 151ms/step - accuracy: 0.9846 - loss: 0.0453 - val_accuracy: 0.9650 - val_loss: 0.1354\nEpoch 43/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 152ms/step - accuracy: 0.9848 - loss: 0.0496 - val_accuracy: 0.9349 - val_loss: 0.1845\nEpoch 44/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 152ms/step - accuracy: 0.9739 - loss: 0.0756 - val_accuracy: 0.9592 - val_loss: 0.1434\nEpoch 45/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 150ms/step - accuracy: 0.9792 - loss: 0.0564 - val_accuracy: 0.9670 - val_loss: 0.1198\nEpoch 46/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 152ms/step - accuracy: 0.9868 - loss: 0.0428 - val_accuracy: 0.9660 - val_loss: 0.1199\nEpoch 47/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 151ms/step - accuracy: 0.9814 - loss: 0.0588 - val_accuracy: 0.9446 - val_loss: 0.1641\nEpoch 48/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 150ms/step - accuracy: 0.9853 - loss: 0.0395 - val_accuracy: 0.9592 - val_loss: 0.1407\nEpoch 49/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 152ms/step - accuracy: 0.9805 - loss: 0.0550 - val_accuracy: 0.9621 - val_loss: 0.1317\nEpoch 50/50\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 150ms/step - accuracy: 0.9838 - loss: 0.0490 - val_accuracy: 0.9747 - val_loss: 0.1233\n\nAverage Training Loss: 0.0504\nAverage Validation Loss: 0.0923\nAverage Training Accuracy: 0.9826\nAverage Validation Accuracy: 0.9749\nAverage Precision: 0.9817\nAverage Recall: 0.9790\nAverage F1 Score: 0.9803\nAverage Jaccard Index: 0.9614\nAverage MCC: 0.9587\nAverage Model Size: 10.58 MB\nAverage Training Time: 1013.84 seconds\nAverage Inference Time: 0.95 seconds\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}